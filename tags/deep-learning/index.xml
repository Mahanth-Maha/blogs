<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Deep Learning on Mahanth Yalla</title><link>https://mahanthyalla.in/blogs/tags/deep-learning/</link><description>Recent content in Deep Learning on Mahanth Yalla</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 05 May 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://mahanthyalla.in/blogs/tags/deep-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Zero-Shot Class Unlearning in Deep Computer Vision Models</title><link>https://mahanthyalla.in/blogs/p/zero-shot-unlearning/</link><pubDate>Mon, 05 May 2025 00:00:00 +0000</pubDate><guid>https://mahanthyalla.in/blogs/p/zero-shot-unlearning/</guid><description>&lt;h1 id="zero-shot-class-unlearning-in-deep-computer-vision-models">&lt;a href="#zero-shot-class-unlearning-in-deep-computer-vision-models" class="header-anchor">&lt;/a>Zero-Shot Class Unlearning in Deep Computer Vision Models
&lt;/h1>&lt;p>Forgetting the Past: Targeted Unlearning in Pretrained Deep Networks for Computer Vision - Project Work for Course : DS265 Deep Learning for Computer Vision (DLCV 2025), IISc Bangalore&lt;/p>
&lt;h2 id="project-overview">&lt;a href="#project-overview" class="header-anchor">&lt;/a>Project Overview
&lt;/h2>&lt;p>This project explores and implements methods for &lt;strong>Machine Unlearning&lt;/strong>, specifically focusing on &lt;strong>Zero-Shot Class Unlearning&lt;/strong> in deep learning models for computer vision tasks. The goal is to enable a pre-trained model to &amp;ldquo;forget&amp;rdquo; specific classes it was originally trained on, without requiring access to the original training data (the &amp;ldquo;zero-shot&amp;rdquo; constraint). This is increasingly important due to data privacy regulations (like GDPR&amp;rsquo;s &amp;ldquo;Right to be Forgotten&amp;rdquo;) and the need to remove outdated or sensitive information from deployed models efficiently.&lt;/p>
&lt;p>The core approach leverages &lt;strong>class impressions&lt;/strong> generated directly from the trained model&amp;rsquo;s parameters. These impressions act as data-free proxies for the classes to be forgotten or retained. An unlearning algorithm, inspired by gradient ascent/descent techniques (like NegGrad+) but adapted for the zero-shot setting using only these impressions, modifies the model&amp;rsquo;s weights to suppress information related to the &amp;ldquo;forget&amp;rdquo; classes while preserving knowledge of the &amp;ldquo;retain&amp;rdquo; classes.&lt;/p>
&lt;p>This repository contains implementations for:&lt;/p>
&lt;ul>
&lt;li>Training baseline models (LeNet5, KarpathyNet, AlexNet, ResNet) on relevant datasets (MNIST, CIFAR-10, ImageNet).&lt;/li>
&lt;li>Training &amp;ldquo;Golden Standard&amp;rdquo; models (retrained from scratch without the forget classes) for comparison.&lt;/li>
&lt;li>Performing zero-shot class unlearning using class impressions derived from the trained models.&lt;/li>
&lt;li>Evaluating the effectiveness of unlearning through accuracy metrics and class-wise comparisons.&lt;/li>
&lt;/ul>
&lt;h2 id="project-structure">&lt;a href="#project-structure" class="header-anchor">&lt;/a>Project Structure
&lt;/h2>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">unlearning_project&lt;/span>&lt;span class="o">/&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">├──&lt;/span> &lt;span class="nx">data&lt;/span>&lt;span class="o">/&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">│&lt;/span> &lt;span class="err">├──&lt;/span> &lt;span class="nx">MNIST&lt;/span>&lt;span class="o">/&lt;/span> &lt;span class="err">#&lt;/span> &lt;span class="nx">MNIST&lt;/span> &lt;span class="nx">dataset&lt;/span> &lt;span class="nf">files&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">idx&lt;/span> &lt;span class="nx">format&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">│&lt;/span> &lt;span class="err">│&lt;/span> &lt;span class="err">└──&lt;/span> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">│&lt;/span> &lt;span class="err">├──&lt;/span> &lt;span class="nx">cifar&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nx">batches&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nx">py&lt;/span>&lt;span class="o">/&lt;/span> &lt;span class="err">#&lt;/span> &lt;span class="nx">CIFAR&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">10&lt;/span> &lt;span class="nx">dataset&lt;/span> &lt;span class="nf">files&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">python&lt;/span> &lt;span class="nx">batches&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">│&lt;/span> &lt;span class="err">│&lt;/span> &lt;span class="err">└──&lt;/span> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">│&lt;/span> &lt;span class="err">└──&lt;/span> &lt;span class="nx">ImageNet&lt;/span>&lt;span class="o">/&lt;/span> &lt;span class="err">#&lt;/span> &lt;span class="nx">ImageNet&lt;/span> &lt;span class="nx">dataset&lt;/span> &lt;span class="nx">files&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">│&lt;/span> &lt;span class="err">│&lt;/span> &lt;span class="err">└──&lt;/span> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">├──&lt;/span> &lt;span class="nx">Learn_LeNet5_Script&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">py&lt;/span> &lt;span class="err">#&lt;/span> &lt;span class="nx">Example&lt;/span> &lt;span class="nx">training&lt;/span> &lt;span class="nf">script&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">can&lt;/span> &lt;span class="nx">be&lt;/span> &lt;span class="nx">adapted&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">├──&lt;/span> &lt;span class="nx">Learn_KarpathyNet_Script&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">py&lt;/span> &lt;span class="err">#&lt;/span> &lt;span class="nx">Example&lt;/span> &lt;span class="nx">training&lt;/span> &lt;span class="nf">script&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">can&lt;/span> &lt;span class="nx">be&lt;/span> &lt;span class="nx">adapted&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">├──&lt;/span> &lt;span class="nx">Learn_KarpathyNet_Golden_Script&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">py&lt;/span> &lt;span class="err">#&lt;/span> &lt;span class="nx">Example&lt;/span> &lt;span class="nx">golden&lt;/span> &lt;span class="nx">standard&lt;/span> &lt;span class="nx">training&lt;/span> &lt;span class="nx">script&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">├──&lt;/span> &lt;span class="nx">Unlearn_LNet_Script&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">py&lt;/span> &lt;span class="err">#&lt;/span> &lt;span class="nx">Unlearning&lt;/span> &lt;span class="nx">script&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="nx">LeNet5&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">├──&lt;/span> &lt;span class="nx">Unlearn_KNet_Script&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">py&lt;/span> &lt;span class="err">#&lt;/span> &lt;span class="nx">Unlearning&lt;/span> &lt;span class="nx">script&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="nx">KarpathyNet&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">├──&lt;/span> &lt;span class="nx">requirements&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">txt&lt;/span> &lt;span class="err">#&lt;/span> &lt;span class="nx">Python&lt;/span> &lt;span class="kn">package&lt;/span> &lt;span class="nx">dependencies&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">└──&lt;/span> &lt;span class="nx">README&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">md&lt;/span> &lt;span class="err">#&lt;/span> &lt;span class="nx">This&lt;/span> &lt;span class="nx">file&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="setup-instructions">&lt;a href="#setup-instructions" class="header-anchor">&lt;/a>Setup Instructions
&lt;/h2>&lt;h3 id="prerequisites">&lt;a href="#prerequisites" class="header-anchor">&lt;/a>Prerequisites
&lt;/h3>&lt;ul>
&lt;li>Git&lt;/li>
&lt;li>Conda (or Miniconda)&lt;/li>
&lt;li>NVIDIA GPU with CUDA drivers (recommended for training larger models)&lt;/li>
&lt;/ul>
&lt;h3 id="1-clone-the-repository">&lt;a href="#1-clone-the-repository" class="header-anchor">&lt;/a>1. Clone the Repository
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">git clone https://github.com/Mahanth-Maha/ZeroShotUnlearning
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">cd&lt;/span> ZeroShotUnlearning
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="2-create-conda-environment">&lt;a href="#2-create-conda-environment" class="header-anchor">&lt;/a>2. Create Conda Environment
&lt;/h3>&lt;p>We recommend using Python 3.10 or later. Create a Conda environment using the provided &lt;code>requirements.txt&lt;/code> file.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Create the environment named &amp;#39;unlearn_env&amp;#39; (or choose your own)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">conda create --name unlearn_env &lt;span class="nv">python&lt;/span>&lt;span class="o">=&lt;/span>3.10 -y
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Activate the environment&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">conda activate unlearn_env
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Install PyTorch with CUDA support (adjust cuda version if needed)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Check PyTorch website (pytorch.org) for the correct command for your system/CUDA version&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Example for CUDA 11.8:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">conda install pytorch torchvision torchaudio pytorch-cuda&lt;span class="o">=&lt;/span>11.8 -c pytorch -c nvidia
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Install other dependencies&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pip install -r requirements.txt
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="3-download-and-prepare-datasets">&lt;a href="#3-download-and-prepare-datasets" class="header-anchor">&lt;/a>3. Download and Prepare Datasets
&lt;/h3>&lt;ul>
&lt;li>&lt;strong>MNIST:&lt;/strong> Download the IDX files (train-images-idx3-ubyte, train-labels-idx1-ubyte, t10k-images-idx3-ubyte, t10k-labels-idx1-ubyte) and place them in &lt;code>./data/MNIST/&lt;/code>.&lt;/li>
&lt;li>&lt;strong>CIFAR-10:&lt;/strong> Download the Python version batches (data_batch_1 to 5, test_batch, batches.meta) and place them in &lt;code>./data/cifar-10-batches-py/&lt;/code>.&lt;/li>
&lt;li>&lt;strong>ImageNet :&lt;/strong> Place your &lt;code>val&lt;/code>, and &lt;code>test&lt;/code> image files into &lt;code>./data/ImageNet/&lt;/code>.
&lt;ul>
&lt;li>image net validation set used is from Kaggle, which can be downloaded from python script&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">kagglehub&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">path&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">kagglehub&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dataset_download&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;titericz/imagenet1k-val&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;Path to dataset files:&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">path&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>&lt;strong>Note:&lt;/strong> The dataset files are not included in this repository due to size constraints. You can download them from their respective sources:&lt;/p>&lt;/blockquote>
&lt;h2 id="usage">&lt;a href="#usage" class="header-anchor">&lt;/a>Usage
&lt;/h2>&lt;h3 id="1-training-original-models">&lt;a href="#1-training-original-models" class="header-anchor">&lt;/a>1. Training Original Models
&lt;/h3>&lt;ul>
&lt;li>
&lt;p>LNet, KNet these are trained with the scripts &lt;code>Learn_LeNet5_Script.py&lt;/code> and &lt;code>Learn_KarpathyNet_Script.py&lt;/code> respectively. These scripts are designed to train the models on the specified datasets (MNIST, CIFAR-10) and save the trained models in the &lt;code>saved_models/&lt;/code> directory.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>AlexNet and ResNet are pretrained models. You can use the &lt;code>torchvision&lt;/code> library to load these models and fine-tune them on your dataset. The training scripts for these models are not provided in this repository, but you can adapt the existing scripts for your needs.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Unlearning works on any other model as long as you have the model architecture and the dataset ready.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="2-training-golden-standard-models-for-comparison">&lt;a href="#2-training-golden-standard-models-for-comparison" class="header-anchor">&lt;/a>2. Training Golden Standard Models (for Comparison)
&lt;/h3>&lt;p>These models are trained from scratch &lt;em>without&lt;/em> the classes intended for forgetting. This provides a benchmark for the unlearning process.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Example (KarpathyNet without classes {3, 4, 8}):&lt;/strong>
&lt;ul>
&lt;li>&lt;strong>Note:&lt;/strong> The forget classes &lt;code>{3, 4, 8}&lt;/code> are currently &lt;strong>hardcoded&lt;/strong> in &lt;code>Learn_KarpathyNet_Golden_Script.py&lt;/code>. You need to &lt;strong>edit the script&lt;/strong> to change the &lt;code>Target_classes&lt;/code> set if you want to forget different classes.&lt;/li>
&lt;li>Run the specific script:
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">python Learn_KarpathyNet_Golden_Script.py -n v1_golden_forget_348 -e &lt;span class="m">100&lt;/span> &lt;span class="c1"># Use a distinct version name&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>Adapt or create similar scripts for other models/forget sets as needed. The output directory will be based on the &lt;code>--net_name&lt;/code> and &lt;code>-n&lt;/code>/&lt;code>--version_name&lt;/code> arguments used in the script.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="3-performing-zero-shot-unlearning">&lt;a href="#3-performing-zero-shot-unlearning" class="header-anchor">&lt;/a>3. Performing Zero-Shot Unlearning
&lt;/h3>&lt;p>The unlearning scripts load a pre-trained model, generate or load class impressions, and then apply the zero-shot unlearning algorithm.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Notebooks (&lt;code>.ipynb&lt;/code>):&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Files like &lt;code>Unlearn_LNet.ipynb&lt;/code> and &lt;code>Unlearn_KNet.ipynb&lt;/code> provide an interactive way to step through the unlearning process, generate class impressions, visualize results, and understand the core logic. Run these using Jupyter Notebook or Jupyter Lab within your activated conda environment.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Scripts (&lt;code>.py&lt;/code>):&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Files like &lt;code>Unlearn_LNet_Script.py&lt;/code> and &lt;code>Unlearn_KNet_Script.py&lt;/code> are designed to run the unlearning process non-interactively.&lt;/li>
&lt;li>&lt;strong>Modify the Scripts:&lt;/strong> You&amp;rsquo;ll need to &lt;strong>edit these scripts&lt;/strong> to specify:
&lt;ul>
&lt;li>&lt;code>net_name&lt;/code> and &lt;code>version_name&lt;/code>: To load the correct pre-trained model from &lt;code>saved_models&lt;/code>.&lt;/li>
&lt;li>&lt;code>target_classes&lt;/code>: A set of class indices to forget (e.g., &lt;code>{1, 2, 3, 4}&lt;/code> or &lt;code>{3, 4, 8}&lt;/code>).&lt;/li>
&lt;li>Hyperparameters like &lt;code>NUM_SAMPLES&lt;/code> for impressions, &lt;code>LEARN_RATE&lt;/code> for unlearning, &lt;code>epochs&lt;/code>, etc.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Run the Script:&lt;/strong>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Example for LeNet (after editing the script for desired target classes)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">python Unlearn_LNet_Script.py
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Example for KarpathyNet (after editing the script)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">python Unlearn_KNet_Script.py
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="output-the-scripts-will-typically">&lt;a href="#output-the-scripts-will-typically" class="header-anchor">&lt;/a>&lt;strong>Output:&lt;/strong> The scripts will typically:
&lt;/h3>&lt;ol>
&lt;li>Load the specified pre-trained model.&lt;/li>
&lt;li>Determine the responsive layer (usually the last learnable one before the classifier).&lt;/li>
&lt;li>Generate or load class impressions for all classes for that layer (saving them to &lt;code>unlearn/&amp;lt;model_name&amp;gt;_&amp;lt;version_name&amp;gt;/class_impressions/&lt;/code>).&lt;/li>
&lt;li>Create forget/retain datasets &lt;em>using the impressions&lt;/em>.&lt;/li>
&lt;li>Instantiate the &lt;code>ZeroShotUnlearner&lt;/code>.&lt;/li>
&lt;li>Run the unlearning optimization loop (modifying the model &lt;em>in memory&lt;/em>).&lt;/li>
&lt;li>Evaluate the &lt;em>unlearned&lt;/em> model on the test set (overall, forget classes, retain classes).&lt;/li>
&lt;li>Generate comparison plots (Original vs. Unlearned class-wise accuracy).&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>&lt;strong>Note:&lt;/strong> The provided unlearning scripts primarily focus on executing the unlearning process and evaluating its effect &lt;em>immediately&lt;/em>. They might not explicitly save the &lt;em>state&lt;/em> of the unlearned model to a separate file. The &lt;code>u_model&lt;/code> variable within the script holds the unlearned state. You could modify the scripts to save &lt;code>u_model.state_dict()&lt;/code> if needed.&lt;/li>
&lt;/ul>
&lt;h2 id="evaluation">&lt;a href="#evaluation" class="header-anchor">&lt;/a>Evaluation
&lt;/h2>&lt;ul>
&lt;li>&lt;strong>Training:&lt;/strong> The scripts starting with &lt;code>Learn&lt;/code> (&lt;code>.py&lt;/code> and &lt;code>.ipynb&lt;/code>) evaluates on the validation set during training and saves logs/plots. Final evaluation on the test set (using the best model checkpoint) is performed at the end.&lt;/li>
&lt;li>&lt;strong>Unlearning:&lt;/strong> The unlearning scripts starting with &lt;code>Unlearn&lt;/code> (&lt;code>.py&lt;/code> and &lt;code>.ipynb&lt;/code>) perform evaluation after the unlearning process:
&lt;ul>
&lt;li>Prints overall accuracy.&lt;/li>
&lt;li>Prints accuracy specifically on the &lt;em>forget&lt;/em> classes (should be close to 0%).&lt;/li>
&lt;li>Prints accuracy specifically on the &lt;em>retain&lt;/em> classes (should be close to the original model&amp;rsquo;s accuracy on these classes, or the golden standard model&amp;rsquo;s accuracy).&lt;/li>
&lt;li>Generates bar plots comparing class-wise accuracies of the original model and the unlearned model.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="note-">&lt;a href="#note-" class="header-anchor">&lt;/a>Note :
&lt;/h3>&lt;ul>
&lt;li>The unlearning process is computationally intensive and may take time, especially for larger models and datasets. Ensure you have sufficient resources (GPU recommended).&lt;/li>
&lt;/ul>
&lt;h3 id="time-complexity">&lt;a href="#time-complexity" class="header-anchor">&lt;/a>Time complexity
&lt;/h3>&lt;p>class impressions generation: is the most time-consuming part of the unlearning process. but it is done only once for each class. The time complexity of generating class impressions is O(n * m), where n is the number of samples in the dataset and m is the number of classes. This is because we need to compute the class impression for each sample in the dataset for each class.&lt;/p>
&lt;p>After generating the class impressions, it is straightforward to compute the forget and retain datasets, and no matter what the number of classes is, the time complexity of this step is O(n), where n is the number of samples in the dataset, for unlearning. The unlearning process itself is O(k * n), where k is the number of epochs and n is the number of samples in the dataset. This is because we need to compute the gradients for each sample in the dataset for each epoch.&lt;/p></description></item></channel></rss>